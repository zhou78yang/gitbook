# 碎片

## 基础概念
* 命令行工具`scrapy`
    * scrapy shell，shell工具，方便调试selector
* Spider类，定义如何爬取某个（些）网站
* Selector，选择器，帮助从网页源码提取数据
* Item，dict的派生类，将抓取数据转换为结构性数据
* Item Loaders，结合了Item和Selector的一个工具，方便进行Item字段的填充
* Item Pipeline，当Item在Spider中被收集之后，它将会被传递到Item Pipeline，一些组件会按照一定的顺序执行对Item的处理
* Feed Export，生成一个带有爬取数据的”输出文件”(通常叫做”输出feed”)，来供其他系统使用。
* Request和Response，请求和响应
    * Request.meta，Request和Response之间的通信
* Link Extractors，从网页中提取你想要follow的链接


## 代码片段
Request.meta，一种提供Request向Response回调函数传参的手段。`response.meta is response.request.meta`
```python
def parse_page1(self, response):
    item = MyItem()
    item['main_url'] = response.url
    request = scrapy.Request("http://www.example.com/some_page.html",
                             callback=self.parse_page2)
    request.meta['item'] = item
    return request

def parse_page2(self, response):
    item = response.meta['item']
    item['other_url'] = response.url
    return item
```

meta的特殊参数：https://scrapy-chs.readthedocs.io/zh_CN/1.0/topics/request-response.html#request-meta-special-keys
